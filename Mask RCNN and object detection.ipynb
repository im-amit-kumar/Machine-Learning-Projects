{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsPath = \"object_detection_classes_coco.txt\"\n",
    "Labels = open(labelsPath).read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightPath = \"frozen_inference_graph.pb\"\n",
    "configPath = \"mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Colors = np.random.randint(100, 255, (len(Labels), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = cv2.dnn.readNetFromTensorflow(weightPath, configPath)\n",
    "image = cv2.imread(\"image2.jpg\")\n",
    "H, W = image.shape[:2]\n",
    "convertedImage = cv2.dnn.blobFromImage(image, swapRB=True, crop=False)\n",
    "net.setInput(convertedImage)\n",
    "(objects, masks) = net.forward([\"detection_out_final\", \"detection_masks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "bicycle\n",
      "bicycle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(objects.shape[2]):\n",
    "    classID = int(objects[0,0, i, 1])\n",
    "    conf = objects[0,0,i,2]\n",
    "    if conf > 0.84:\n",
    "        print(Labels[classID])\n",
    "        \n",
    "        box = objects[0,0,i, 3:7] * np.array([W,H, W,H])\n",
    "        startX, startY, endX, endY = box.astype(\"int\")\n",
    "        \n",
    "        boxW = endX - startX\n",
    "        boxH = endY - startY\n",
    "        \n",
    "        mask = masks[i, classID]\n",
    "        mask = cv2.resize(mask, (boxW, boxH))\n",
    "        mask = (mask > 0.4)\n",
    "        \n",
    "        roi = image[startY:endY, startX:endX]\n",
    "        roi = roi[mask]\n",
    "        \n",
    "        color = Colors[classID]\n",
    "        B,G,R = color\n",
    "        ColorMask = ((0.4 * color) + (0.6 * roi)).astype(\"uint8\")\n",
    "        image[startY:endY, startX:endX][mask] = ColorMask\n",
    "        \n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), (int(B),int(G),int(R)), 2)\n",
    "        text = Labels[classID] + \"--\" + str(conf)\n",
    "        #cv2.putText(image, text, (startX, startY-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsPath = \"coco.names\"\n",
    "Labels = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "weightPath = \"yolov3.weights\"\n",
    "configPath = \"yolov3.cfg\"\n",
    "\n",
    "Colors = np.random.randint(100, 255, (len(Labels), 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightPath)\n",
    "image = cv2.imread(\"image2.jpg\")\n",
    "H, W = image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = net.getLayerNames()\n",
    "ucl = net.getUnconnectedOutLayers()\n",
    "LayerName = []\n",
    "for i in ucl:\n",
    "    LayerName.append(layers[i[0]-1])\n",
    "\n",
    "convertedImage = cv2.dnn.blobFromImage(image, 1/255, (416, 416), swapRB=True, crop=False)\n",
    "net.setInput(convertedImage)\n",
    "prediction = net.forward(LayerName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "bicycle\n",
      "bicycle\n"
     ]
    }
   ],
   "source": [
    "for output in prediction:\n",
    "    for detection in output:\n",
    "        score = detection[5:]\n",
    "        conf = np.max(score)\n",
    "        classId = np.argmax(score)\n",
    "        if conf > 0.97:\n",
    "            print(Labels[classId])\n",
    "            Cx,Cy,w,h = (detection[:4] * np.array([W,H,W,H])).astype(\"int\")\n",
    "            x = int(Cx - (w//2))\n",
    "            y = int(Cy - (h//2))\n",
    "            cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = prediction[1][1][5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Video Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "             \"sofa\", \"train\", \"tvmonitor\",\"smartphone\",\"hand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weightPath = \"MobileNetSSD_deploy.caffemodel\"\n",
    "configPath = \"MobileNetSSD_deploy.prototxt.txt\"\n",
    "\n",
    "Colors = np.random.randint(100, 255, (len(CLASSES), 3))\n",
    "\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(configPath, weightPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    H, W = frame.shape[:2]\n",
    "    image = cv2.resize(frame, (300, 300))\n",
    "    convertedImage = cv2.dnn.blobFromImage(image, 0.007843, (300, 300), 127.5)\n",
    "    net.setInput(convertedImage)\n",
    "    detection = net.forward()\n",
    "    \n",
    "    for i in range(detection.shape[2]):\n",
    "        classID = int(detection[0,0, i, 1])\n",
    "        conf = detection[0,0,i,2]\n",
    "        if conf > 0.84:\n",
    "            labels = CLASSES[int(classID)]\n",
    "            \n",
    "            color = Colors[classID]\n",
    "            B,G,R = color\n",
    "      \n",
    "            box = detection[0,0,i, 3:7] * np.array([W,H, W,H])\n",
    "            startX, startY, endX, endY = box.astype(\"int\")\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (int(B),int(G),int(R)), 3)\n",
    "            cv2.putText(frame, labels, (startX, startY-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (int(B),int(G),int(R)), 3)\n",
    "    cv2.imshow(\"Image\", frame)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "    \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
